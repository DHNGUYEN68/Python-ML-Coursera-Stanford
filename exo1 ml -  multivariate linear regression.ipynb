{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## This Python notebook implements the linear regression from scratch for multivariate (multi features)\n",
    "## using gradient descent method\n",
    "## Credit : Machine Learning course (assignment #1) from Prof Andrew Ng (free course on Coursera/Stanford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# load data from csv file \n",
    "data=np.genfromtxt('ex1data2.txt', delimiter=',')\n",
    "# Two features\n",
    "X=data[:,0:2]\n",
    "\n",
    "# Target feature \n",
    "y=data[:,2:3]\n",
    "\n",
    "# count of examples (number of houses)\n",
    "m=len(y)\n",
    "\n",
    "## for debug\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.10400e+03 3.00000e+00 3.99900e+05]\n",
      " [1.60000e+03 3.00000e+00 3.29900e+05]\n",
      " [2.40000e+03 3.00000e+00 3.69000e+05]\n",
      " [1.41600e+03 2.00000e+00 2.32000e+05]\n",
      " [3.00000e+03 4.00000e+00 5.39900e+05]\n",
      " [1.98500e+03 4.00000e+00 2.99900e+05]\n",
      " [1.53400e+03 3.00000e+00 3.14900e+05]\n",
      " [1.42700e+03 3.00000e+00 1.98999e+05]\n",
      " [1.38000e+03 3.00000e+00 2.12000e+05]]\n"
     ]
    }
   ],
   "source": [
    "## print 10 records\n",
    "a=X[0:9,:]\n",
    "b=y[0:9,:]\n",
    "c=np.concatenate((a,b),axis=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.104e+03 3.000e+00]\n",
      " [1.600e+03 3.000e+00]\n",
      " [2.400e+03 3.000e+00]\n",
      " [1.416e+03 2.000e+00]\n",
      " [3.000e+03 4.000e+00]\n",
      " [1.985e+03 4.000e+00]\n",
      " [1.534e+03 3.000e+00]\n",
      " [1.427e+03 3.000e+00]\n",
      " [1.380e+03 3.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print (X[0:9,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.104e+03 3.000e+00]\n",
      " [1.600e+03 3.000e+00]\n",
      " [2.400e+03 3.000e+00]\n",
      " [1.416e+03 2.000e+00]\n",
      " [3.000e+03 4.000e+00]\n",
      " [1.985e+03 4.000e+00]\n",
      " [1.534e+03 3.000e+00]\n",
      " [1.427e+03 3.000e+00]\n",
      " [1.380e+03 3.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# features normalise\n",
    "X_norm = np.copy(X)  # make a copy of values\n",
    "#X_norm = X  # this is a reference / address\n",
    "mu = np.zeros(np.size(X[0,:]))\n",
    "sigma = np.zeros(np.size(X[0,:]))\n",
    "\n",
    "def featureNormalize(X_norm, mu, sigma):\n",
    "  global X\n",
    "  num_features = np.size(X[0,:])\n",
    "  for i in range(num_features):\n",
    "        mu[i]    =  np.mean(X[:,i])\n",
    "        sigma[i] =  np.std(X[:,i])\n",
    "        X_norm[:,i] = (X[:,i] - mu[i]) / sigma[i] \n",
    "       \n",
    "print (X[0:9,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.86202619e+02 7.52842809e-01]\n",
      "[2000.68085106    3.17021277]\n"
     ]
    }
   ],
   "source": [
    "featureNormalize(X_norm, mu, sigma)\n",
    "# Expected std\n",
    "# Feature #1 794.7023535 Feature #2 0.760981887\n",
    "print (sigma)\n",
    "\n",
    "# Expected Average\n",
    "# Feature #1 2000.680851  Feature #2 3.170212766\n",
    "print (mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.13141542 -0.22609337]\n",
      " [ 1.         -0.5096407  -0.22609337]\n",
      " [ 1.          0.5079087  -0.22609337]\n",
      " [ 1.         -0.74367706 -1.5543919 ]\n",
      " [ 1.          1.27107075  1.10220517]\n",
      " [ 1.         -0.01994505  1.10220517]\n",
      " [ 1.         -0.59358852 -0.22609337]\n",
      " [ 1.         -0.72968575 -0.22609337]\n",
      " [ 1.         -0.78946678 -0.22609337]]\n"
     ]
    }
   ],
   "source": [
    "ones=np.ones(m).reshape(m,1)\n",
    "X_train = (np.append(ones, X_norm, axis=1))\n",
    "# Append the first columns of 1 in X matrix (artificial feature for the intercept)\n",
    "X_train.shape\n",
    "print (X_train[0:9,:])  # normalised values for training with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose some alpha value\n",
    "# Some gradient descent settings\n",
    "alpha = 0.02\n",
    "num_iters = 400\n",
    "J_history = np.zeros(num_iters).reshape(num_iters,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros(3).reshape(3,1)\n",
    "# initialise the parameters (two for univariate linear regression) a*x + b = y\n",
    "# theta[0] is b : intercept\n",
    "# theta[1] is  slope1\n",
    "# theta[2] is  slope2\n",
    "\n",
    "# Init Theta and Run Gradient Descent \n",
    "#theta = zeros(3, 1);\n",
    "#[theta, J_history] = gradientDescentMulti(X_train, y, theta, alpha, num_iters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "def computeCostMulti(X_train,y,theta):\n",
    "  #COMPUTECOST Compute cost for linear regression\n",
    "  #   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the\n",
    "  #   parameter for linear regression to fit the data points in X and y\n",
    "\n",
    "  # Initialize some useful values\n",
    "  m = len(y)\n",
    "  # You need to return the following variables correctly \n",
    "  J = 0;\n",
    "  # ====================== YOUR CODE HERE ======================\n",
    "  # Instructions: Compute the cost of a particular choice of theta\n",
    "  #               You should set J to the cost.\n",
    "\n",
    "  #In math : predictions =  X_train * theta\n",
    "  predictions =  np.matmul(X_train,theta)\n",
    "  square_err = np.power((predictions - y),2)\n",
    "  J = 1/(2*m)* np.sum(square_err)\n",
    "  # least square method : square the difference to take the absolute value\n",
    "  return J\n",
    "\n",
    "# =========================================================================\n",
    "\n",
    "#J_history = np.zeros(1500).reshape(1500,1)\n",
    "# for debug\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "#GRADIENTDESCENTMULTI Performs gradient descent to learn theta\n",
    "#   theta = GRADIENTDESCENTMULTI(x, y, theta, alpha, num_iters) updates theta by\n",
    "#   taking num_iters gradient steps with learning rate alpha\n",
    "  global J_history\n",
    "# Initialize some useful values\n",
    "  m = len(y)\n",
    "# number of training examples\n",
    "  J_history = np.zeros(num_iters).reshape(num_iters, 1)\n",
    "  for iter in range(num_iters):\n",
    "    predictions = np.matmul(X,theta)\n",
    "    updates = np.matmul(X.T,(predictions - y))\n",
    "    theta = theta - alpha * (1/m) * updates\n",
    "    J_history[iter]=computeCostMulti(X, y, theta)\n",
    "  return(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "J=computeCostMulti(X_train, y, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65591548106.45744\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(J)\n",
    "print(theta)\n",
    "## cost with the null parameters (defauted null values in initialisation of theta variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAERCAYAAAB4jRxOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22cb549da90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = gradientDescentMulti(X_train, y, theta, alpha, num_iters)\n",
    "x_vals = np.linspace(0,num_iters+1,num_iters)\n",
    "#min_y = J_history.min()\n",
    "#max_y = J_history.max()\n",
    "#plt.axis([0,400,min_y, max_y])\n",
    "plt.plot(x_vals,J_history,'-')\n",
    "plt.xlabel(\"Numbers of iterations\")\n",
    "plt.ylabel(\"Cost J\")\n",
    "plt.show()\n",
    "#print(J_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[340307.35772969]\n",
      " [107757.47433209]\n",
      " [ -4888.35338493]]\n"
     ]
    }
   ],
   "source": [
    "print(theta)\n",
    "# the values match with polyfit (moreless)\n",
    "#expected values\n",
    "# 340307.357730\n",
    "# 108788.316675\n",
    "# -4807.166967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least cost:2044542613.2133398\n"
     ]
    }
   ],
   "source": [
    "JJ=computeCostMulti(X_train, y, theta)\n",
    "print(\"Least cost:\"+repr(JJ))\n",
    "# check the least cost - debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price of a 1650 sq-ft, 3 br house using gradient descent 293348.0221781551\n"
     ]
    }
   ],
   "source": [
    "# Estimate the price of a 1650 sq-ft, 3 br house\n",
    "price = 0; # You should change this\n",
    "element = np.array([1,(1650 - mu[0])/sigma[0],(3 - mu[1])/sigma[1]])\n",
    "price = np.matmul(element, theta)\n",
    "\n",
    "print('Predicted price of a 1650 sq-ft, 3 br house using gradient descent ' + repr(price[0]))\n",
    "# expect value  $293377.233014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalEqn(X, y):\n",
    "#NORMALEQN Computes the closed-form solution to linear regression \n",
    "#  NORMALEQN(X,y) computes the closed-form solution to linear \n",
    "#   regression using the normal equations.    \n",
    "  global theta\n",
    "  theta = np.zeros(3).reshape(3,1)\n",
    "  XT0 = np.matmul(X.T,X)\n",
    "  XT1 = np.matmul(X.T,y)\n",
    "  Inv_M = np.linalg.pinv(XT0)\n",
    "  theta = np.matmul(Inv_M,XT1)\n",
    "  #theta = np.matmul(np.linalg.pinv(np.matmul(X.T,X)), (np.matmul(X.T,y)))\n",
    "  return (theta)\n",
    "   # Math formula : theta = pinv(X' * X) * X' * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price of a 1650 sq-ft, 3 br house using gradient descent 178125474.9455257\n"
     ]
    }
   ],
   "source": [
    "# Estimate the price of a 1650 sq-ft, 3 br house\n",
    "price = 0; # You should change this\n",
    "element = np.array([1,1650,3])\n",
    "price = np.matmul(element, theta)\n",
    "\n",
    "print('Predicted price of a 1650 sq-ft, 3 br house using gradient descent ' + repr(price[0]))\n",
    "# expect value  $293081.464335"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
